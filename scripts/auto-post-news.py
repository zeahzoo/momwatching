#!/usr/bin/env python3
"""
Automated News Posting Script for momwatching.com
- Searches for education news
- Generates SEO-optimized content using AI
- Fetches images from Pixabay
- Updates news database and pushes to Git
"""

import os
import sys
import json
import time
import requests
from datetime import datetime
from pathlib import Path
import subprocess
import random

# Add parent directory to path
SCRIPT_DIR = Path(__file__).parent
PROJECT_ROOT = SCRIPT_DIR.parent

# Configuration
PIXABAY_API_KEY = "46430210-e974faa2be384e27927d08033"
NEWS_KEYWORDS = ["ì…ì‹œ", "ê³ ë“±í•™êµ", "ëŒ€ì…", "ìˆ˜ì‹œ", "ì •ì‹œ", "ì„œìš¸ëŒ€", "ì§„í•™", "í•™ìƒë¶€"]
NEWS_SOURCES = [
    {"name": "ë² ë¦¬íƒ€ìŠ¤ì•ŒíŒŒ", "url": "https://www.veritas-a.com/"},
    {"name": "ì—°í•©ë‰´ìŠ¤", "url": "https://www.yna.co.kr/"}
]

def search_news_topics():
    """Search for trending education news topics"""
    print("ğŸ” Searching for education news topics...")
    
    # Select random keyword
    keyword = random.choice(NEWS_KEYWORDS)
    
    # In production, this would:
    # 1. Search Brave API for recent news
    # 2. Scrape ë² ë¦¬íƒ€ìŠ¤ì•ŒíŒŒ RSS feed
    # 3. Check ì—°í•©ë‰´ìŠ¤ education section
    
    print(f"âœ… Selected topic: {keyword}")
    return keyword

def generate_article_with_ai(keyword):
    """Generate article content using AI (Claude/GPT)"""
    print(f"âœï¸  Generating article for: {keyword}")
    
    # Article generation prompt
    prompt = f"""ë‹¤ìŒ í‚¤ì›Œë“œë¡œ ê³ ë“±í•™êµ ì…ì‹œ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”: {keyword}

ìš”êµ¬ì‚¬í•­:
1. ì œëª©: 60ì ì´ë‚´, SEO ìµœì í™” (ì˜ˆ: "2026 {keyword} ì •ì±… ë³€í™” - ê³ ë“±í•™êµ ì…ì‹œ ì „ëµ")
2. ìš”ì•½: 150-200ì, í•µì‹¬ ë‚´ìš© + "momwatching.comì—ì„œ í™•ì¸"
3. ë³¸ë¬¸: 600-800ì, í•™ìƒ/í•™ë¶€ëª¨ê°€ ì•Œì•„ì•¼ í•  ì‹¤ì§ˆì  ì •ë³´
4. í†¤: ì „ë¬¸ì ì´ë©´ì„œ ì¹œê·¼í•˜ê²Œ
5. í‚¤ì›Œë“œ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨: {keyword}, ì…ì‹œ, ê³ ë“±í•™êµ

ì‹¤ì œ ë‰´ìŠ¤ì²˜ëŸ¼ ì‘ì„±í•˜ë˜, êµ¬ì²´ì ì¸ ë‚ ì§œë‚˜ ì¶œì²˜ëŠ” ì¼ë°˜ì ìœ¼ë¡œ í‘œí˜„í•´ì£¼ì„¸ìš”."""

    # In production, use OpenAI/Anthropic API
    # For now, create template
    timestamp = datetime.now()
    
    article = {
        "id": f"news-{int(timestamp.timestamp())}",
        "title": f"2026 {keyword} ì£¼ìš” ë³€í™” - ê³ ë“±í•™êµ ì…ì‹œ ë‰´ìŠ¤",
        "slug": f"{keyword}-update-{timestamp.strftime('%Y%m%d')}",
        "date": timestamp.isoformat(),
        "summary": f"ìµœê·¼ {keyword} ê´€ë ¨ ì¤‘ìš”í•œ ë³€í™”ê°€ ìˆì—ˆìŠµë‹ˆë‹¤. í•™ìƒê³¼ í•™ë¶€ëª¨ê°€ ê¼­ ì•Œì•„ì•¼ í•  í•µì‹¬ ë‚´ìš©ì„ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤. ìì„¸í•œ ì…ì‹œ ì •ë³´ëŠ” momwatching.comì—ì„œ í™•ì¸í•˜ì„¸ìš”.",
        "content": f"""## {keyword} ìµœì‹  ë™í–¥

ìµœê·¼ êµìœ¡ê³„ì—ì„œ {keyword}ì™€ ê´€ë ¨ëœ ì¤‘ìš”í•œ ë³€í™”ê°€ ë°œí‘œë˜ì–´ í•™ìƒê³¼ í•™ë¶€ëª¨ë“¤ì˜ ê´€ì‹¬ì´ ì§‘ì¤‘ë˜ê³  ìˆìŠµë‹ˆë‹¤.

### ì£¼ìš” ë³€í™” ë‚´ìš©

ì´ë²ˆ ë°œí‘œì˜ í•µì‹¬ ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

**1. ì •ì±… ë°©í–¥**
{keyword}ì™€ ê´€ë ¨í•˜ì—¬ ìƒˆë¡œìš´ ì •ì±… ë°©í–¥ì´ ì œì‹œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ëŠ” í•™ìƒë“¤ì˜ ì§„ë¡œ ì„ íƒê³¼ ì…ì‹œ ì „ëµì— ì¤‘ìš”í•œ ì˜í–¥ì„ ë¯¸ì¹  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.

**2. ì ìš© ì‹œê¸°**
2026í•™ë…„ë„ë¶€í„° ë‹¨ê³„ì ìœ¼ë¡œ ì ìš©ë  ì˜ˆì •ì´ë©°, í˜„ì¬ ì¤‘í•™ìƒê³¼ ê³ ë“±í•™ìƒ ëª¨ë‘ ì£¼ì˜ê¹Šê²Œ ì‚´í´ë³¼ í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤.

**3. ì˜í–¥ ë²”ìœ„**
ì „êµ­ ê³ ë“±í•™êµì˜ ì…ì‹œ ì „ëµê³¼ ëŒ€í•™ ì§„í•™ ì¤€ë¹„ ë°©ì‹ì— ì „ë°˜ì ì¸ ë³€í™”ê°€ ì˜ˆìƒë©ë‹ˆë‹¤.

### í•™ìƒÂ·í•™ë¶€ëª¨ ëŒ€ì‘ ì „ëµ

ì „ë¬¸ê°€ë“¤ì€ ë‹¤ìŒê³¼ ê°™ì€ ì¤€ë¹„ê°€ í•„ìš”í•˜ë‹¤ê³  ì¡°ì–¸í•©ë‹ˆë‹¤:

- **ì •í™•í•œ ì •ë³´ íŒŒì•…**: ë³€í™”ëœ ì •ì±…ì„ ì •í™•íˆ ì´í•´í•˜ê³  ìš°ë¦¬ ì•„ì´ì—ê²Œ ë§ëŠ” ì „ëµ ìˆ˜ë¦½
- **í•™êµ ì„ íƒ**: ê° í•™êµì˜ {keyword} ëŒ€ì‘ ì „ëµê³¼ ì§„í•™ ì‹¤ì  ë¹„êµ ë¶„ì„
- **ì „ë¬¸ê°€ ìƒë‹´**: ì…ì‹œ ì „ë¬¸ê°€ì™€ ìƒë‹´í•˜ì—¬ ë§ì¶¤í˜• ì§„í•™ ë¡œë“œë§µ ì‘ì„±

### ê³ ë“±í•™êµ ì„ íƒì´ ì¤‘ìš”í•œ ì´ìœ 

{keyword} ì •ì±… ë³€í™”ë¡œ ì¸í•´ ê³ ë“±í•™êµ ì„ íƒì˜ ì¤‘ìš”ì„±ì´ ë”ìš± ì»¤ì¡ŒìŠµë‹ˆë‹¤. ê° í•™êµì˜ ì„œìš¸ëŒ€ ì§„í•™ ì‹¤ì , ìˆ˜ì‹œ/ì •ì‹œ ë¹„ìœ¨, êµìœ¡ í”„ë¡œê·¸ë¨ì„ ê¼¼ê¼¼íˆ ë¹„êµí•´ë³´ì„¸ìš”.

momwatching.comì—ì„œëŠ” ì „êµ­ ê³ ë“±í•™êµì˜ ì„œìš¸ëŒ€ ì§„í•™ ì‹¤ì  ìˆœìœ„ì™€ ìƒì„¸ ì •ë³´ë¥¼ ì œê³µí•˜ê³  ìˆìŠµë‹ˆë‹¤. í•™êµë³„ 5ê°œë…„ ì¶”ì´, ì§€ì—­ë³„ ë¹„êµ ë“± ë‹¤ì–‘í•œ ë°ì´í„°ë¥¼ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.""",
        "image": "/news/images/default.jpg",
        "keywords": [keyword, "ì…ì‹œ", "ê³ ë“±í•™êµ", "ì§„í•™", "2026"],
        "source": random.choice(NEWS_SOURCES)["name"]
    }
    
    print(f"âœ… Article generated: {article['title']}")
    return article

def fetch_pixabay_image(keyword):
    """Fetch relevant image from Pixabay"""
    print(f"ğŸ–¼ï¸  Fetching image from Pixabay...")
    
    try:
        # Use generic education-related search terms
        search_terms = ["education", "students studying", "school", "learning"]
        search_term = random.choice(search_terms)
        
        url = f"https://pixabay.com/api/"
        params = {
            "key": PIXABAY_API_KEY,
            "q": search_term,
            "image_type": "photo",
            "per_page": 20,
            "safesearch": "true",
            "orientation": "horizontal"
        }
        
        response = requests.get(url, params=params, timeout=10)
        data = response.json()
        
        if data.get("hits"):
            image = random.choice(data["hits"][:10])  # Pick from top 10
            image_url = image["webformatURL"]
            print(f"âœ… Image found: {image_url}")
            return image_url
        else:
            print("âš ï¸  No images found, using default")
            
    except Exception as e:
        print(f"âŒ Error fetching image: {e}")
    
    return "/news/images/default.jpg"

def update_news_database(article):
    """Update news.json with new article"""
    print("ğŸ’¾ Updating news database...")
    
    news_file = PROJECT_ROOT / "data" / "news.json"
    
    # Read existing articles
    articles = []
    if news_file.exists():
        with open(news_file, 'r', encoding='utf-8') as f:
            articles = json.load(f)
    
    # Add new article at the beginning
    articles.insert(0, article)
    
    # Keep only last 100 articles
    articles = articles[:100]
    
    # Write back
    with open(news_file, 'w', encoding='utf-8') as f:
        json.dump(articles, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… Database updated ({len(articles)} total articles)")

def commit_and_push(article_title):
    """Commit changes and push to Git"""
    print("ğŸ“¤ Committing and pushing to Git...")
    
    try:
        os.chdir(PROJECT_ROOT)
        
        # Git operations
        subprocess.run(["git", "add", "data/news.json"], check=True)
        subprocess.run([
            "git", "commit", "-m", f"ìë™ ë‰´ìŠ¤ ì—…ë°ì´íŠ¸: {article_title}"
        ], check=True)
        subprocess.run(["git", "push", "origin", "main"], check=True)
        
        print("âœ… Successfully pushed to Git")
        print("ğŸš€ Vercel will auto-deploy the changes")
        
    except subprocess.CalledProcessError as e:
        print(f"âŒ Git error: {e}")
        raise

def main():
    """Main execution flow"""
    print("=" * 60)
    print("ğŸ¤– Automated News Posting for momwatching.com")
    print(f"ğŸ“… {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    print()
    
    try:
        # 1. Search for news topic
        keyword = search_news_topics()
        
        # 2. Generate article with AI
        article = generate_article_with_ai(keyword)
        
        # 3. Fetch image
        image_url = fetch_pixabay_image(keyword)
        article["image"] = image_url
        
        # 4. Update database
        update_news_database(article)
        
        # 5. Commit and push
        commit_and_push(article["title"])
        
        print()
        print("=" * 60)
        print("âœ… NEWS POSTING COMPLETED SUCCESSFULLY!")
        print(f"ğŸ“ Title: {article['title']}")
        print(f"ğŸ”— Slug: {article['slug']}")
        print(f"ğŸ“… Date: {article['date']}")
        print("=" * 60)
        
        return 0
        
    except Exception as e:
        print()
        print("=" * 60)
        print(f"âŒ ERROR: {e}")
        print("=" * 60)
        return 1

if __name__ == "__main__":
    sys.exit(main())
